{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'output_masks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4de6c35de135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet50_coco_best_v2.1.0.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# load retinanet model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# if the model is not converted to an inference model, use the line below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras_retinanet/models/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, backbone_name)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/_impl/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/_impl/keras/models.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0;34m'Maybe you meant to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[0;32m--> 324\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/_impl/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0mglobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mglobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sequential'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   return deserialize_keras_object(\n\u001b[0m\u001b[1;32m     60\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/_impl/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'custom_objects'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         return cls.from_config(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             custom_objects=dict(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mnode_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0mprevious_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collect_previous_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m             \u001b[0muser_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_all_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m_collect_previous_mask\u001b[0;34m(input_tensors)\u001b[0m\n\u001b[1;32m   2843\u001b[0m             \u001b[0minbound_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2845\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2846\u001b[0m             \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Node' object has no attribute 'output_masks'"
     ]
    }
   ],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow\n",
    "import keras\n",
    "import keras_retinanet\n",
    "\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "from keras_retinanet.utils.gpu import setup_gpu\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# adjust this to point to your downloaded/trained model\n",
    "# models can be downloaded here: https://github.com/fizyr/keras-retinanet/releases\n",
    "#model_path = os.path.join('..', 'snapshots', 'resnet50_coco_best_v2.1.0.h5')\n",
    "model_path = os.path.join('resnet50_coco_best_v2.1.0.h5')\n",
    "# load retinanet model\n",
    "model = models.load_model(model_path, backbone_name='resnet50')\n",
    "\n",
    "# if the model is not converted to an inference model, use the line below\n",
    "# see: https://github.com/fizyr/keras-retinanet#converting-a-training-model-to-inference-model\n",
    "#model = models.convert_model(model)\n",
    "\n",
    "#print(model.summary())\n",
    "\n",
    "# load label to names mapping for visualization purposes\n",
    "labels_to_names = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', \n",
    "                   6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', \n",
    "                   12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', \n",
    "                   19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', \n",
    "                   25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', \n",
    "                   31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', \n",
    "                   36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', \n",
    "                   41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', \n",
    "                   48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', \n",
    "                   54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', \n",
    "                   60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', \n",
    "                   66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', \n",
    "                   72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', \n",
    "                   78: 'hair drier', 79: 'toothbrush'}\n",
    "# use this to change which GPU to use\n",
    "#gpu = 0\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "#setup_gpu(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing /home/hatsune/cv/keras-retinanet\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from keras-retinanet==1.0.0) (8.0.1)\n",
      "Requirement already satisfied: cython in /usr/lib/python3/dist-packages (from keras-retinanet==1.0.0) (0.29.21)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from keras-retinanet==1.0.0) (1.19.3)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from keras-retinanet==1.0.0) (4.4.0.46)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from keras-retinanet==1.0.0) (1.15.0)\n",
      "Collecting keras-resnet==0.2.0\n",
      "  Downloading keras-resnet-0.2.0.tar.gz (9.3 kB)\n",
      "Collecting keras>=2.2.4\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/lib/python3/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.5.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (5.3.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.1.0)\n",
      "Collecting progressbar2\n",
      "  Downloading progressbar2-3.53.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting python-utils>=2.3.0\n",
      "  Downloading python_utils-2.4.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: keras-retinanet, keras-resnet\n",
      "  Building wheel for keras-retinanet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-retinanet: filename=keras_retinanet-1.0.0-cp38-cp38-linux_x86_64.whl size=176794 sha256=4040db927d84acde0e1362c70a0f181a16591ae9b8c8fcdc237e57cce466c21a\n",
      "  Stored in directory: /home/hatsune/.cache/pip/wheels/1b/cd/fb/94692aea6f0a1ece9b843f767bbe9c2a1d142efc9433834a94\n",
      "  Building wheel for keras-resnet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20486 sha256=4ac586135d33290a30ec37b6e20b2fda0b17f6a0a65313473705afc8c1e8a02a\n",
      "  Stored in directory: /home/hatsune/.cache/pip/wheels/be/90/98/9d455f04a7ca277366b36c660c89d171ff5abb7bdd8a8b8e75\n",
      "Successfully built keras-retinanet keras-resnet\n",
      "Installing collected packages: python-utils, keras, progressbar2, keras-resnet, keras-retinanet\n",
      "\u001b[33m  WARNING: The scripts retinanet-convert-model, retinanet-debug, retinanet-evaluate and retinanet-train are installed in '/home/hatsune/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed keras-2.4.3 keras-resnet-0.2.0 keras-retinanet-1.0.0 progressbar2-3.53.1 python-utils-2.4.0\n"
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "\n",
    "git_repo_url = 'https://github.com/fizyr/keras-retinanet'\n",
    "retina_net_dir = 'keras-retinanet'\n",
    "\n",
    "if not exists(retina_net_dir):\n",
    "    # clone \"depth 1\" will only get the latest copy of the relevant files.\n",
    "    !git clone -q --recurse-submodules --depth 1 $git_repo_url\n",
    "    # build\n",
    "    !cd {retina_net_dir} && pip install .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import subprocess\n",
    "import os\n",
    "from playsound import playsound\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "cv2.setUseOptimized(True)\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=6)\n",
    "#vs = VideoStream(0).start()\n",
    "#vs = VideoStream(\"http://10.1.30.40:8080/video\").start()\n",
    "time.sleep(3.0)\n",
    "fps = FPS().start()\n",
    "y = 0\n",
    "# loop over the frames from the video stream\n",
    "kl_ = 0\n",
    "key = \"\"\n",
    "input_shape = (255,255,3)\n",
    "num_classes = 2\n",
    "imagelist = \"\"\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#ansver_list = read file\n",
    "\n",
    "for image in imagelist:\n",
    "    # grab the frame from the threaded video stream and resize it\n",
    "    # to have a maximum width of 400 pixels\n",
    "    #frame = vs.read()\n",
    "    #frame = imutils.resize(frame, width=720)\n",
    "    #(height, width) = frame.shape[:2]\n",
    "    # Let's get the starting pixel coordiantes (top left of cropped top)\n",
    "    #start_row, start_col = int(0), int(0)\n",
    "    # Let's get the ending pixel coordinates (bottom right of cropped top)\n",
    "    #end_row, end_col = int(height * .5), int(width)\n",
    "    #cropped_top = frame[start_row:end_row , start_col:end_col]\n",
    "    #print (start_row, end_row)\n",
    "    #print (start_col, end_col)\n",
    "\n",
    "    im = image\n",
    "    ss.setBaseImage(im)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    rects = ss.process()\n",
    "    imOut = im.copy()\n",
    "    for i, rect in (enumerate(rects)):\n",
    "        x, y, w, h = rect\n",
    "        #     print(x,y,w,h)\n",
    "        #     imOut = imOut[x:x+w,y:y+h]\n",
    "        img = imOut[x:x+w,y:y+h]\n",
    "        #cv2.rectangle(imOut, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        # суём в нейронку и сравниваем с положительными результатами...\n",
    "        true_rect = ansver_list[kl_].split(\",\")\n",
    "        if ((x == true_rect[0] )|(x > true_rect[0] & x < true_rect[0] + 10)):\n",
    "            if ((y == true_rect[0])|(y > true_rect[0] & y < true_rect[0] + 10)):\n",
    "                if ((h == true_rect[0] )|(h > true_rect[0] & h < true_rect[0] + 10)):\n",
    "                    if ((w == true_rect[0] )|(w > true_rect[0] & w < true_rect[0] + 10)):\n",
    "                        # значит правдивый результат\n",
    "                        pass\n",
    "    # plt.figure()\n",
    "    #plt.imshow(imOut)\n",
    "    \n",
    "    \n",
    "    #cv2.rectangle(frame, (0, 0), (150, 100), COLORS[0], 2)\n",
    "    #cv2.rectangle(frame, (0, 250), (150, 350), COLORS[2], 2)\n",
    "\n",
    "    # Let's get the starting pixel coordiantes (top left of cropped bottom)\n",
    "    #start_row, start_col = int(0), int(0)\n",
    "    # Let's get the ending pixel coordinates (bottom right of cropped bottom)\n",
    "    #end_row, end_col = int(150), int(100)\n",
    "    #cropped_bot = frame[start_row:end_row , start_col:end_col]\n",
    "    #print (start_row, end_row)\n",
    "    #print (start_col, end_col)\n",
    "    \n",
    "\n",
    "    #cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    # update the FPS counter\n",
    "    #fps.update()\n",
    "    kl_ += 1\n",
    "    #if (kl_ >= 10):\n",
    "    #    kl_ = 0\n",
    "    #    os.system('clear')\n",
    "\n",
    "# stop the timer and display FPS information\n",
    "#fps.stop()\n",
    "#print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "#print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "# do a bit of cleanup\n",
    "#cv2.destroyAllWindows()\n",
    "#vs.stop()\n",
    "\n",
    "#cv2.imshow(\"Cropped Top\", cropped_top) \n",
    "#cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import argparse\n",
    "import requests\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-u\", \"--urls\", required=True,\n",
    "\thelp=\"path to file containing image URLs\")\n",
    "ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "\thelp=\"path to output directory of images\")\n",
    "args = vars(ap.parse_args())\n",
    "# grab the list of URLs from the input file, then initialize the\n",
    "# total number of images downloaded thus far\n",
    "rows = open(args[\"urls\"]).read().strip().split(\"\\n\")\n",
    "total = 0\n",
    "\n",
    "# loop the URLs\n",
    "for url in rows:\n",
    "\ttry:\n",
    "\t\t# try to download the image\n",
    "\t\tr = requests.get(url, timeout=60)\n",
    "\t\t# save the image to disk\n",
    "\t\tp = os.path.sep.join([args[\"output\"], \"{}.jpg\".format(\n",
    "\t\t\tstr(total).zfill(8))])\n",
    "\t\tf = open(p, \"wb\")\n",
    "\t\tf.write(r.content)\n",
    "\t\tf.close()\n",
    "\t\t# update the counter\n",
    "\t\tprint(\"[INFO] downloaded: {}\".format(p))\n",
    "\t\ttotal += 1\n",
    "\t# handle if any exceptions are thrown during the download process\n",
    "\texcept:\n",
    "\t\tprint(\"[INFO] error downloading {}...skipping\".format(p))\n",
    "# loop over the image paths we just downloaded\n",
    "for imagePath in paths.list_images(args[\"output\"]):\n",
    "\t# initialize if the image should be deleted or not\n",
    "\tdelete = False\n",
    "\t# try to load the image\n",
    "\ttry:\n",
    "\t\timage = cv2.imread(imagePath)\n",
    "\t\t# if the image is `None` then we could not properly load it\n",
    "\t\t# from disk, so delete it\n",
    "\t\tif image is None:\n",
    "\t\t\tdelete = True\n",
    "\t# if OpenCV cannot load the image then the image is likely\n",
    "\t# corrupt so we should delete it\n",
    "\texcept:\n",
    "\t\tprint(\"Except\")\n",
    "\t\tdelete = True\n",
    "\t# check to see if the image should be deleted\n",
    "\tif delete:\n",
    "\t\tprint(\"[INFO] deleting {}\".format(imagePath))\n",
    "\t\tos.remove(imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import subprocess\n",
    "import os\n",
    "from playsound import playsound\n",
    "\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=6)\n",
    "vs = VideoStream(0).start()\n",
    "#vs = VideoStream(\"http://10.1.30.40:8080/video\").start()\n",
    "time.sleep(3.0)\n",
    "fps = FPS().start()\n",
    "y = 0\n",
    "# loop over the frames from the video stream\n",
    "kl_ = 0\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream and resize it\n",
    "    # to have a maximum width of 400 pixels\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=720)\n",
    "    (height, width) = frame.shape[:2]\n",
    "    # Let's get the starting pixel coordiantes (top left of cropped top)\n",
    "    #start_row, start_col = int(0), int(0)\n",
    "    # Let's get the ending pixel coordinates (bottom right of cropped top)\n",
    "    #end_row, end_col = int(height * .5), int(width)\n",
    "    #cropped_top = frame[start_row:end_row , start_col:end_col]\n",
    "    #print (start_row, end_row)\n",
    "    #print (start_col, end_col)\n",
    "\n",
    "    cv2.rectangle(frame, (0, 0), (150, 100), COLORS[0], 2)\n",
    "    cv2.rectangle(frame, (0, 250), (150, 350), COLORS[2], 2)\n",
    "\n",
    "    # Let's get the starting pixel coordiantes (top left of cropped bottom)\n",
    "    start_row, start_col = int(0), int(0)\n",
    "    # Let's get the ending pixel coordinates (bottom right of cropped bottom)\n",
    "    end_row, end_col = int(150), int(100)\n",
    "    cropped_bot = frame[start_row:end_row , start_col:end_col]\n",
    "    #print (start_row, end_row)\n",
    "    #print (start_col, end_col)\n",
    "    \n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    # update the FPS counter\n",
    "    fps.update()\n",
    "    kl_ += 1\n",
    "    if (kl_ >= 10):\n",
    "        kl_ = 0\n",
    "        os.system('clear')\n",
    "\n",
    "# stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "# do a bit of cleanup\n",
    "#cv2.destroyAllWindows()\n",
    "vs.stop()\n",
    "\n",
    "#cv2.imshow(\"Cropped Top\", cropped_top) \n",
    "#cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
